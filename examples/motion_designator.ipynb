{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7861047a",
   "metadata": {},
   "source": [
    "# Motion Designator\n",
    "Motion designator are similar to action designator, but unlike action designator, motion designator represent atomic tasks. While designators usually use vague descriptions, Motion Designators operate with specific parameteres.\n",
    "\n",
    "Since motion designators perform motions on the robot, we need a robot which we can use. Therefore, we will create a BulletWorld as well as a PR2 robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd813bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "\n",
    "world = BulletWorld()\n",
    "pr2 = Object(\"pr2\", \"robot\", \"pr2.urdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458b80c-65f7-4b33-8d8f-bee9333f57a2",
   "metadata": {},
   "source": [
    "The following publishes the resources to RvizWeb.\n",
    "(Skip if running locally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eea972-ca72-4545-b2f1-be98904581df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.ros.tf_broadcaster import TFBroadcaster\n",
    "from pycram.ros.viz_marker_publisher import VizMarkerPublisher\n",
    "\n",
    "tf_broadcaster = TFBroadcaster()\n",
    "viz_publisher = VizMarkerPublisher()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1094ec",
   "metadata": {},
   "source": [
    "## Move\n",
    "Move is used to let the robot drive to the given target pose. Motion designators are used in the same way as the other designator, first create a description then resolve it to the actual designator and lastly, perform the resolved designator.\n",
    "\n",
    "Performing motion designator verifies the given parameters and passes them to the respective robot drivers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa29029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.pose import Pose\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))\n",
    "    \n",
    "    motion_desig = motion_description.resolve()\n",
    "    \n",
    "    motion_desig.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b20fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world.reset_bullet_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53126483",
   "metadata": {},
   "source": [
    "## MoveTCP\n",
    "MoveTCP is used to move the tool center point (TCP) of the given arm to the target position specified by the parameter. Like any designator we start by creating a description and then resolving and performing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7389f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveTCPMotion\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveTCPMotion(target=Pose([0.5, 0.6, 0.6], [0, 0, 0, 1]), arm=\"left\")\n",
    "    \n",
    "    motion_description.resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89526e9c",
   "metadata": {},
   "source": [
    "## Looking\n",
    "Looking motion designator adjusts the robot state such that the cameras point towards the target pose. Although this motion designator takes the target as position and orientation, in reality only the position is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a554f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import LookingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = LookingMotion(target=Pose([1, 1, 1], [0, 0, 0, 1]))\n",
    "    \n",
    "    motion_description.resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9490c51",
   "metadata": {},
   "source": [
    "## Move Gripper\n",
    "Move gripper moves the gripper of an arm to one of two states. The states can be ```open``` and ```close```, which open and close the gripper respectivly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb872b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveGripperMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveGripperMotion(motion=\"open\", gripper=\"left\")\n",
    "    \n",
    "    motion_description.resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252c19b",
   "metadata": {},
   "source": [
    "## Detecting \n",
    "This is the motion designator implementation of detecting, if an object with the given object type is in the field of view (FOV) this motion designator will return an object designator describing the object.\n",
    "\n",
    "Since we need an object that we can detect, we will spawn a milk for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e559b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "milk = Object(\"milk\", \"milk\", \"milk.stl\", pose=Pose([1.5, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5f031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import DetectingMotion, LookingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    LookingMotion(target=Pose([1.5, 0, 1], [0, 0, 0, 1])).resolve().perform()\n",
    "    \n",
    "    motion_description = DetectingMotion(object_type=\"milk\")\n",
    "    \n",
    "    obj = motion_description.resolve().perform()\n",
    "    \n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6232110",
   "metadata": {},
   "source": [
    "## Move Arm Joints\n",
    "This motion designator moves one or both arms. Movement targets can either be a dictionary with joint name as key and target pose as value or a pre-defined configuration like 'park'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfed680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveArmJointsMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveArmJointsMotion(left_arm_config=\"park\", right_arm_poses={\"r_shoulder_pan_joint\": -0.7})\n",
    "    \n",
    "    motion_description.resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b2e0c",
   "metadata": {},
   "source": [
    "## World State Detecting\n",
    "World state detecting is also used to detect objects, however, the object is not required to be in the FOV of the robot. As long as the object is somewhere in the beliefe state (BulletWorld) a resolved object designator will be returned.\n",
    "\n",
    "Sine we want to detect something we will spawn an object that we can detect. If you already spawned the milk the the previous example you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73eba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "milk = Object(\"milk\", \"milk\", \"milk.stl\", pose=Pose([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552e2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import WorldStateDetectingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = WorldStateDetectingMotion(object_type=\"milk\")\n",
    "    \n",
    "    obj = motion_description.resolve().perform()\n",
    "    \n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6539d",
   "metadata": {},
   "source": [
    "## Move Joints\n",
    "Move joints can move any number of joints of the robot, the designator takes two lists as parameter. The first list are the names of all joints that should be moved and the second list are the positions to which the joints should be moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd39c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveJointsMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveJointsMotion(names=[\"torso_lift_joint\", \"r_shoulder_pan_joint\"], positions=[0.2, -1.2])\n",
    "    \n",
    "    motion_description.resolve().perform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
